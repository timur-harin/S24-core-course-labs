# Kubernetes StatefulSet

## Task 2

```bash
kubectl get po,sts,svc,pvc
```

```bash
NAME                                       READY   STATUS    RESTARTS          AGE
pod/python-app-0                          1/1     Running   0                 3m23s
pod/python-app-1                           1/1     Running   0                 3m23s
pod/vault-0                                1/1     Running   245 (5m34s ago)   15d
pod/vault-agent-injector-dbfc5cd77-nxqpn   1/1     Running   224 (5m44s ago)   15d

NAME                          READY   AGE
statefulset.apps/app-python   2/2     3m23s
statefulset.apps/vault        1/1     15d

NAME                               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE
service/python-app                 NodePort    10.103.0.15     <none>        80:31810/TCP        3m23s
service/kubernetes                 ClusterIP   10.96.0.1       <none>        443/TCP             16d
service/vault                      ClusterIP   10.106.179.35   <none>        8200/TCP,8201/TCP   15d
service/vault-agent-injector-svc   ClusterIP   10.105.4.169    <none>        443/TCP             15d
service/vault-internal             ClusterIP   None            <none>        8200/TCP,8201/TCP   15d

NAME                                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/data-python-app-0   Bound    pvc-e3c4137d-0e95-4b32-a71b-5056b36ab2c2   1Mi        RWO            standard       3m23s
persistentvolumeclaim/data-python-app-1   Bound    pvc-96cd7256-87fa-4959-b673-a1c4e145fb42   1Mi        RWO            standard       3m23s
```

```bash
kubectl exec python-app-0 -- cat /app/data/visits.txt
kubectl exec python-app--1 -- cat /app/data/visits.txt
```

```bash
62
45
```


## Why difference?

```
The two pods, python-app-0 and python-app-1, do not receive the same number of visits due to Kubernetes' load balancing feature. This is because Kubernetes' load balancer distributes incoming network traffic across multiple instances, but it does not always split the traffic evenly.

The specific load balancing algorithm used in this case is likely based on the default algorithm used by Kubernetes, which may not always distribute traffic equally between the pods. This can result in one pod (python-app-0) receiving more requests than the other (python-app-1).

The reason for this is likely because the initial requests were directed to python-app-0 through the minikube service command, while the second pod (python-app-1) was primarily used for healthcheck requests. If a different load balancing algorithm were used, the requests might have been split more evenly between the two pods.
```

## Why ordering guarantees are unnecessary for your app


```
In a StatefulSet, ordering guarantees are unnecessary for your app because the uniqueness of each Pod's identity is guaranteed by the StatefulSet controller. This means that each Pod will have a unique identifier and will be created and managed in a specific order.

However, if your app requires strict ordering of operations, such as a specific sequence of events or actions, you may need to implement additional logic within your app to handle this. The StatefulSet controller itself does not provide ordering guarantees for the operations performed by the Pods, such as launching or terminating them.
```

# Bonus

## Extra app

Change for values and statefulset.yamk

## Two strategies

```
Kubernetes provides two update strategies for StatefulSets:

RollingUpdate: This is the default strategy for StatefulSets. It incrementally replaces Pods one-by-one, starting with the Pods with the highest ordinal index. If a Pod update fails, no new updates are started. This strategy ensures zero downtime during the update, but requires a good health check mechanism to prevent propagation of a bad update.

OnDelete: With this strategy, the StatefulSet controller will not automatically update the Pods. The update is triggered only when the Pods are manually deleted by the user. This strategy allows for manual control over the update process and can be useful in situations where you want to carefully control the timing and order of Pod updates.
```